# ğŸš€ Experimento de Monitoreo Heartbeat - TÃ¡ctica de Disponibilidad

Este experimento demuestra la implementaciÃ³n de una **tÃ¡ctica de arquitectura de software** para mejorar la **disponibilidad** del sistema mediante el uso de un **monitor tipo heartbeat**, **ping**, **monitor**

## ğŸ“‹ Tabla de Contenidos

- [ğŸ¯ Objetivo del Experimento](#-objetivo-del-experimento)
- [ğŸ—ï¸ Arquitectura del Sistema](#ï¸-arquitectura-del-sistema)
- [âš™ï¸ Prerrequisitos](#ï¸-prerrequisitos)
- [ğŸš€ ConfiguraciÃ³n del Entorno](#-configuraciÃ³n-del-entorno)
- [ğŸ“Š Componentes del Sistema](#-componentes-del-sistema)
- [ğŸ”§ EjecuciÃ³n del Experimento](#-ejecuciÃ³n-del-experimento)
- [ğŸ§ª Pruebas y ValidaciÃ³n](#-pruebas-y-validaciÃ³n)
- [ğŸ“ˆ VisualizaciÃ³n y Monitoreo](#-visualizaciÃ³n-y-monitoreo)
- [ğŸ› ï¸ SoluciÃ³n de Problemas](#ï¸-soluciÃ³n-de-problemas)
- [ğŸ“½ï¸ Video de Evidencia](#ï¸-video-de-evidencia)
- [ğŸ“š Referencias](#-referencias)

## ğŸ¯ Objetivo del Experimento

El objetivo es implementar y demostrar cÃ³mo funciona una **tÃ¡ctica de monitoreo heartbeat** que:

- âœ… Detecta fallos en servicios de forma temprana
- âœ… Proporciona mÃ©tricas de disponibilidad en tiempo real
- âœ… Genera alertas automÃ¡ticas cuando se detectan problemas
- âœ… Mejora la capacidad de respuesta ante incidentes
- âœ… Cantidad de errores detectados en la ejecucion

## ğŸ—ï¸ Arquitectura del Experimento

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Grafana       â”‚â—„â”€â”€â”€â”¤   Prometheus    â”‚â—„â”€â”€â”€â”¤ Servicio|Pedidos â”‚
â”‚  (Dashboard)    â”‚    â”‚   (Monitor)     â”‚    â”‚   (Flask App)    â”‚
â”‚  Puerto: 3000   â”‚    â”‚  Puerto: 9090   â”‚    â”‚  Puerto: 8000    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      
```

### Flujo de Monitoreo Heartbeat:
1. **Prometheus** envÃ­a requests cada 10 segundos a `/metrics` del servicio
2. **Docker healthcheck** verifica `/health` cada 30 segundos
3. **Grafana** visualiza mÃ©tricas y genera alertas

## âš™ï¸ Prerrequisitos

### Software Requerido

| Software | VersiÃ³n MÃ­nima | PropÃ³sito |
|----------|----------------|-----------|
| **Docker Desktop** | 20.x+ | ContainerizaciÃ³n |
| **Docker Compose** | 2.x+ | OrquestaciÃ³n de contenedores |
| **Git** | 2.x+ | Control de versiones |
| **curl** | 7.x+ | Pruebas de endpoints |

Los comandos se deben ejecutar en Gitbash si el sistema operativo es Windows

### VerificaciÃ³n de Prerrequisitos

Ejecuta los siguientes comandos para verificar que tienes todo instalado:

```bash
# Verificar Docker
docker --version
# Salida esperada: Docker version 24.x.x, build xxxxxxx

# Verificar Docker Compose
docker compose --version
# Salida esperada: Docker Compose version v2.x.x

# Verificar Git
git --version
# Salida esperada: git version 2.x.x

# Verificar curl
curl --version
# Salida esperada: curl 7.x.x
```

### Puertos Requeridos

AsegÃºrate de que los siguientes puertos estÃ©n disponibles:

| Puerto | Servicio | DescripciÃ³n |
|--------|----------|-------------|
| **3000** | Grafana | Dashboard de monitoreo |
| **8000** | Flask App | Servicio de pedidos |
| **9090** | Prometheus | Motor de mÃ©tricas |


```bash
# Verificar puertos disponibles (Windows)
netstat -an | findstr "3000 8000 9090 1025 8025"
# No debe mostrar ninguna salida si los puertos estÃ¡n libres
```

## ğŸš€ ConfiguraciÃ³n del Entorno

### Paso 1: Clonar el Repositorio

```bash
# Clonar el repositorio
git clone https://github.com/Laurarestrepo03/MISW4202-202514-Grupo-5.git

# Navegar al directorio del proyecto
cd MISW4202-202514-Grupo-5
```

### Paso 2: Navegar al Directorio del Experimento

```bash
# Ir al directorio especÃ­fico del experimento
cd experimento/pedidos

```

### Paso 3: Verificar Archivos del Proyecto

```bash
# Listar archivos del proyecto
ls -la

# Debes ver estos archivos:
# - docker-compose.yml (configuraciÃ³n de contenedores)
# - app.py (aplicaciÃ³n Flask)
# - Dockerfile (imagen del servicio)
# - prometheus.yml (configuraciÃ³n de Prometheus)
# - requirements.txt (dependencias Python)
# - dashboard_grafana.json (dashboard predefinido)
```

## ğŸ“Š Componentes del Sistema

### 1. **Servicio de Pedidos (Flask)**
- **Archivo**: `app.py`
- **Puerto**: 8000
- **Endpoints**:
  - `GET /health` - Endpoint de salud (heartbeat)
  - `GET /orders` - Servicio principal (con fallos simulados)
  - `GET /metrics` - MÃ©tricas para Prometheus

### 2. **Prometheus (Monitor)**
- **Imagen**: `prom/prometheus`
- **Puerto**: 9090
- **ConfiguraciÃ³n**: `prometheus.yml`
- **FunciÃ³n**: Recolecta mÃ©tricas cada 10 segundos

### 3. **Grafana (Dashboard)**
- **Imagen**: `grafana/grafana`
- **Puerto**: 3000
- **Credenciales**: admin/admin
- **FunciÃ³n**: Visualiza mÃ©tricas y alertas


## ğŸ”§ EjecuciÃ³n del Experimento

### EjecuciÃ³n Completa

```bash
# 1. AsegÃºrate de estar en el directorio correcto
cd experimento/pedidos

# 2. Construir y levantar todos los servicios
docker compose up --build -d

# 3. Verificar que todos los contenedores estÃ©n funcionando
docker compose ps
```

### Estado Esperado de los Contenedores

```
NAME                 STATUS
grafana-monitor      Up X seconds
pedidos-pedidos-1    Up X seconds (healthy)
prometheus-monitor   Up X seconds
smtp-monitor         Up X seconds (healthy)
```

## ğŸ§ª Pruebas y ValidaciÃ³n

### 1. Verificar el Heartbeat

```bash
# Probar endpoint de salud
curl http://localhost:8000/health

# Respuesta esperada:
# {"status":"healthy","timestamp":"2025-09-07T14:42:17.900702"}
```

### 2. Probar SimulaciÃ³n de Fallos (Ejecutar experimento)
Para ejecutar el comando hay que ejecutar el archivo **test_endpoint.sh**

En caso de ejecutarlo manualmente se puede ejecutar con el siguiente comando bash que repite un ciclo 10 veces

```bash
# Ejecutar mÃºltiples requests. Si la persona quiere hacer una prueba mas larga se puede alterar el ciclo a > 10
start_time=$(date +"%Y-%m-%d %H:%M:%S")
echo "Start time: $start_time"
for i in {1..10}; do
  echo "Request $i"
  time curl -w "HTTP Response Code: %{http_code}\n" http://localhost:8000/orders
  echo "--"
done
end_time=$(date +"%Y-%m-%d %H:%M:%S")
echo "End time: $end_time"
```

**Respuestas Posibles:**
- âœ… **Ã‰xito**: `{"orders":[...], "total_count":3}`
- âŒ **Fallo**: `{"error":"Internal Server Error"}`

### 3. Verificar MÃ©tricas

```bash
# Ver mÃ©tricas de Prometheus
curl http://localhost:8000/metrics | grep flask_http_request_total

# Salida esperada (ejemplo):
# flask_http_request_total{method="GET",status="200"} 5.0
# flask_http_request_total{method="GET",status="500"} 3.0
```

## ğŸ“ˆ VisualizaciÃ³n y Monitoreo

### Aclaracion sobre analisis de metricas
Las metricas se visualizan por Graphana pero por su funcionamiento en caso de que dos errores 500 se repitan, no los va a contar como dos errores, sino como un error continuo. Por eso para analizar rigurosamente cada respuesta se debe tener en cuenta la respuesta como error 500 exactamente. 


### Acceso a las Interfaces

1. **Prometheus** (Motor de mÃ©tricas):
   - URL: http://localhost:9090
   - Queries Ãºtiles:
     - `flask_http_request_total` - Total de requests
     - `flask_http_request_duration_seconds` - Tiempo de respuesta
     - `up` - Estado de los servicios

2. **Grafana** (Dashboard):
   - URL: http://localhost:3000
   - Usuario: `admin`
   - ContraseÃ±a: `admin`

### Configurar Dashboard en Grafana

1. Acceder a Grafana (http://localhost:3000)
2. Login con admin/admin
3. Configurar datasource como **"Prometheus"** (http://prometheus:9090) y seleccionar **Save&test**
4. Ir **Dashboards**, **New**â†’ **"Import"**
5. Importar el archivo del repositorio `dashboard_grafana.json`
6. Pegar y hacer clic en **"Load"**
7. Seleccionar en time range desde el valor impreso de `start_time` hasta **now** o el valor impreso de `end_time`
8. Para una visualizacion mas rigurosa se puede configurar en el time range la hora de inicio y hora de final del experimento para tener una visualizacion exacta

> Nota: si se configura `start_time` como el tiempo de inicio inmediatamente despuÃ©s de iniciar las peticiones, puede que el dashboard muestre un error de tiempo. Esto es por el delay que tiene Grafana, pero se soluciona despuÃ©s de unos momentos. Por esto, se recomienda dejar los valores predeterminados mientras se hacen las peticiones, y cuando se haya terminado de ejecutar el script, ajustar el rango de tiempo a `start_time` y `end_time`

## ğŸ› ï¸ SoluciÃ³n de Problemas

### Problema: Contenedores no inician

```bash
# Verificar logs
docker compose logs

# Verificar puertos ocupados
netstat -tlnp | grep -E "3000|8000|9090|1025|8025"

# Limpiar y reiniciar
docker compose down -v
docker compose up --build -d
```

### Problema: Healthcheck fallando

```bash
# Verificar logs del servicio
docker compose logs pedidos

# Probar endpoint manualmente
curl -v http://localhost:8000/health

# Reiniciar servicio especÃ­fico
docker compose restart pedidos
```

### Problema: Prometheus no encuentra targets

```bash
# Verificar configuraciÃ³n
cat prometheus.yml

# Verificar conectividad de red
docker network ls
docker network inspect monitoring
```

### Problema: Grafana no muestra datos

1. Verificar datasource en Grafana
2. URL debe ser: `http://prometheus:9090` (no localhost)
3. Verificar que Prometheus estÃ© recolectando mÃ©tricas

## ğŸ” Comandos Ãštiles

### Docker Management

```bash
# Ver logs de todos los servicios
docker compose logs

# Ver logs de un servicio especÃ­fico
docker compose logs -f pedidos

# Reiniciar un servicio
docker compose restart prometheus

# Detener todos los servicios
docker compose down

# Limpiar completamente (incluyendo volÃºmenes)
docker compose down -v

# Ver recursos utilizados
docker compose ps
docker system df
```

### Monitoreo en Tiempo Real

```bash
# Ver logs en vivo
docker compose logs -f

# Monitor de recursos
docker stats

# Verificar salud de contenedores
watch -n 5 'docker compose ps'
```

## ğŸ“½ï¸ Video de Evidencia
El video con la evidencia del experimento puede ser visto [aquÃ­](https://www.youtube.com/watch?v=NShVUZKHbWw) o dando click a la imagen.

<a href="https://www.youtube.com/watch?v=NShVUZKHbWw"> <img width="500" alt="image" src="https://github.com/user-attachments/assets/adadd742-4aa2-4e98-a68e-b614a9a7d431"/> </a>

## ğŸ“š Referencias

### TecnologÃ­as Utilizadas

- [Docker](https://docs.docker.com/) - ContainerizaciÃ³n
- [Prometheus](https://prometheus.io/docs/) - Monitoreo y mÃ©tricas
- [Grafana](https://grafana.com/docs/) - VisualizaciÃ³n
- [Flask](https://flask.palletsprojects.com/) - Framework web Python


### Enlaces Ãštiles

- [Prometheus Query Language](https://prometheus.io/docs/prometheus/latest/querying/basics/)
- [Grafana Dashboard Creation](https://grafana.com/docs/grafana/latest/dashboards/)
- [Docker Compose Reference](https://docs.docker.com/compose/compose-file/)

---

# ğŸ” Experimento 2 - Sistema de AuditorÃ­a con Base de Datos

Este segundo experimento demuestra la implementaciÃ³n de un **sistema de auditorÃ­a automÃ¡tica** usando **triggers de base de datos** para registrar todas las operaciones realizadas sobre los datos crÃ­ticos del sistema.

## ğŸ¯ Objetivo del Experimento 2

El objetivo es implementar y demostrar cÃ³mo funciona un **sistema de auditorÃ­a automÃ¡tica** que:

- âœ… Registra automÃ¡ticamente todas las operaciones de inserciÃ³n, actualizaciÃ³n y eliminaciÃ³n
- âœ… Mantiene un log de auditorÃ­a con informaciÃ³n detallada de cada transacciÃ³n
- âœ… Proporciona trazabilidad completa de las operaciones realizadas
- âœ… Permite consultar el historial de cambios en tiempo real
- âœ… Mejora la seguridad y compliance del sistema

## ğŸ—ï¸ Arquitectura del Experimento 2

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Flask App     â”‚â—„â”€â”€â”€â”¤   PostgreSQL    â”‚â—„â”€â”€â”€â”¤  Trigger Functionâ”‚
â”‚  (API REST)     â”‚    â”‚   (Database)    â”‚    â”‚  (audit_log_fn)  â”‚
â”‚  Puerto: 8000   â”‚    â”‚  Puerto: 5432   â”‚    â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â–º audit_log (tabla)
                                 â”‚
                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â–º pedidos (tabla)
```

### Flujo de AuditorÃ­a:
1. **API REST** recibe peticiÃ³n POST para insertar pedido
2. **PostgreSQL** ejecuta INSERT en tabla `pedidos`
3. **Trigger automÃ¡tico** se activa y ejecuta funciÃ³n de auditorÃ­a
4. **FunciÃ³n de auditorÃ­a** inserta registro en tabla `audit_log`
5. **API REST** permite consultar estadÃ­sticas de auditorÃ­a

## ğŸ“Š Componentes del Experimento 2

### 1. **API de Pedidos (Flask)**
- **Archivo**: `experimento2/pedidos/app.py`
- **Puerto**: 8000
- **Endpoints**:
  - `POST /insertar_pedido` - Inserta un nuevo pedido en la base de datos
  - `GET /audit_result` - Consulta estadÃ­sticas de pedidos y auditorÃ­a

### 2. **Base de Datos (PostgreSQL)**
- **Imagen**: `postgres:16`
- **Puerto**: 5432
- **Base de datos**: `medy_supply`
- **Tablas principales**:
  - `pedidos` - Almacena los pedidos del sistema
  - `audit_log` - Registra todas las operaciones de auditorÃ­a

### 3. **Sistema de Triggers**
- **Trigger**: `pedidos_audit_trigger`
- **FunciÃ³n**: `audit_log_pedidos_fn()`
- **ActivaciÃ³n**: AFTER INSERT, UPDATE, DELETE en tabla `pedidos`

## ğŸš€ EjecuciÃ³n del Experimento 2

### Paso 1: Navegar al Directorio del Experimento 2

```bash
# Ir al directorio especÃ­fico del experimento 2
cd experimento2/pedidos
```

### Paso 2: Verificar Archivos del Proyecto

```bash
# Listar archivos del proyecto
ls -la

# Debes ver estos archivos:
# - docker-compose.yml (configuraciÃ³n de contenedores)
# - app.py (aplicaciÃ³n Flask con API REST)
# - Dockerfile-APP (imagen del servicio Flask)
# - Dockerfile-DB (imagen personalizada de PostgreSQL)
# - init.sql (script de inicializaciÃ³n de base de datos)
# - requirements.txt (dependencias Python)
```

### Paso 3: Ejecutar el Experimento

```bash
# Construir y levantar todos los servicios
docker-compose up --build

# Verificar que los contenedores estÃ©n funcionando
docker-compose ps
```

### Estado Esperado de los Contenedores

```
NAME               STATUS
pedidos-db-1       Up X seconds (healthy)
pedidos-pedidos-1  Up X seconds
```

## ğŸ§ª Pruebas y ValidaciÃ³n del Experimento 2

### 1. Verificar Estado Inicial

```bash
# Consultar estado inicial de auditorÃ­a
curl http://localhost:8000/audit_result

# Respuesta esperada:
# {"total_audit":0,"total_pedidos":0}
```

### 2. Insertar Pedidos de Prueba

```bash
# Insertar primer pedido
curl -X POST http://localhost:8000/insertar_pedido \
  -H "Content-Type: application/json" \
  -d '{"nombre":"Aspirina","cantidad":50,"precio":15.99}'

# Respuesta esperada:
# {"mensaje":"Pedido insertado"}

# Insertar segundo pedido
curl -X POST http://localhost:8000/insertar_pedido \
  -H "Content-Type: application/json" \
  -d '{"nombre":"Ibuprofeno","cantidad":30,"precio":25.50}'

# Insertar tercer pedido
curl -X POST http://localhost:8000/insertar_pedido \
  -H "Content-Type: application/json" \
  -d '{"nombre":"Paracetamol","cantidad":100,"precio":12.75}'
```

### 3. Verificar AuditorÃ­a AutomÃ¡tica

```bash
# Consultar estadÃ­sticas despuÃ©s de las inserciones
curl http://localhost:8000/audit_result

# Respuesta esperada:
# {"total_audit":3,"total_pedidos":3}
```

### 4. Verificar Funcionamiento de Triggers

La auditorÃ­a se ejecuta automÃ¡ticamente. Cada inserciÃ³n en la tabla `pedidos` genera un registro en `audit_log` con:

- **pedido_id**: ID del pedido afectado
- **accion**: Tipo de operaciÃ³n (INSERT, UPDATE, DELETE)
- **usuario**: Usuario que realizÃ³ la operaciÃ³n
- **message**: Mensaje descriptivo de la operaciÃ³n
- **fecha**: Timestamp de cuando ocurriÃ³ la operaciÃ³n

## ğŸ”§ Estructura de Datos

### Tabla `pedidos`
```sql
CREATE TABLE pedidos (
    pedido_id SERIAL PRIMARY KEY,
    nombre VARCHAR(100) NOT NULL,
    cantidad INT NOT NULL,
    precio FLOAT NOT NULL,
    fecha_pedido TIMESTAMP
);
```

### Tabla `audit_log`
```sql
CREATE TABLE audit_log (
    id SERIAL PRIMARY KEY,
    pedido_id INT,
    accion VARCHAR(100),
    usuario VARCHAR(200),
    message VARCHAR(200),
    fecha TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

## ğŸ“ˆ AnÃ¡lisis de Resultados

### MÃ©tricas Clave del Experimento 2

1. **Total de Pedidos**: NÃºmero de registros en la tabla `pedidos`
2. **Total de AuditorÃ­as**: NÃºmero de registros en la tabla `audit_log`
3. **Consistencia**: Verificar que cada operaciÃ³n genera su registro de auditorÃ­a
4. **Trazabilidad**: Capacidad de rastrear todas las operaciones realizadas

### ValidaciÃ³n de la AuditorÃ­a

```bash
# Ejemplo de consulta de validaciÃ³n
# Para verificar que cada pedido tiene su registro de auditorÃ­a:

# 1. Insertar varios pedidos
for i in {1..5}; do
  curl -X POST http://localhost:8000/insertar_pedido \
    -H "Content-Type: application/json" \
    -d '{"nombre":"Producto'$i'","cantidad":'$((10+i))',"precio":'$((10+i))'.99}'
  sleep 1
done

# 2. Verificar resultados
curl http://localhost:8000/audit_result

# Debe mostrar: {"total_audit":5,"total_pedidos":5}
```

## ğŸ“½ï¸ Comando para Detener el Experimento 2

```bash
# Detener todos los servicios
docker-compose down

# Limpiar completamente (incluyendo volÃºmenes)
docker-compose down -v
```

## ğŸ” VerificaciÃ³n de Resultados del Experimento 2

### Resultados Esperados

1. âœ… **InserciÃ³n Exitosa**: Cada pedido se inserta correctamente en la base de datos
2. âœ… **AuditorÃ­a AutomÃ¡tica**: Cada inserciÃ³n genera automÃ¡ticamente un registro de auditorÃ­a
3. âœ… **Consistencia de Datos**: El nÃºmero de pedidos coincide con el nÃºmero de registros de auditorÃ­a
4. âœ… **Trazabilidad Completa**: Todos los cambios quedan registrados con timestamp y usuario
5. âœ… **API Funcional**: Los endpoints responden correctamente y proporcionan estadÃ­sticas actualizadas

---

